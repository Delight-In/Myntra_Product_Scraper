Exploratory Data Analysis (EDA) on audio datasets focuses on extracting meaningful features, visualizations, and insights from audio signals. These signals can come in different forms (e.g., speech, music, noise) and can be processed for both supervised and unsupervised learning tasks. Below are **100 EDA techniques** specifically for audio datasets:

---

### **1. Basic Audio File Exploration**
1. **Load Audio File**
    ```python
    import librosa
    audio, sr = librosa.load('audio_file.wav', sr=None)
    ```

2. **Check Audio Properties**
    ```python
    duration = librosa.get_duration(y=audio, sr=sr)
    print(f"Duration: {duration} seconds")
    print(f"Sampling Rate: {sr}")
    ```

3. **Visualize Audio Waveform**
    ```python
    import matplotlib.pyplot as plt
    plt.plot(audio)
    plt.title("Audio Waveform")
    plt.show()
    ```

4. **Display Spectrogram**
    ```python
    plt.specgram(audio, Fs=sr)
    plt.title("Spectrogram")
    plt.show()
    ```

5. **Check Audio File Size**
    ```python
    import os
    file_size = os.path.getsize('audio_file.wav') / (1024 * 1024)  # MB
    print(f"Audio file size: {file_size:.2f} MB")
    ```

---

### **2. Basic Audio Signal Analysis**
6. **Plot Signal Over Time**
    ```python
    times = librosa.times_like(audio)
    plt.plot(times, audio)
    plt.title('Audio Signal Over Time')
    plt.show()
    ```

7. **Plot a Zoomed-In View of the Audio**
    ```python
    plt.plot(audio[:1000])
    plt.title("Zoomed-in Audio Waveform")
    plt.show()
    ```

8. **Visualize Zero-Crossing Rate**
    ```python
    zero_crossings = librosa.feature.zero_crossing_rate(audio)
    plt.plot(zero_crossings[0])
    plt.title("Zero-Crossing Rate")
    plt.show()
    ```

9. **Visualize Signal Envelope**
    ```python
    envelope = librosa.onset.onset_strength(y=audio, sr=sr)
    plt.plot(envelope)
    plt.title("Signal Envelope")
    plt.show()
    ```

10. **Calculate Root Mean Square Error (RMS)**
    ```python
    rms = librosa.feature.rms(y=audio)
    plt.plot(rms[0])
    plt.title("Root Mean Square (RMS) Energy")
    plt.show()
    ```

---

### **3. Frequency Domain Analysis**
11. **Plot Fourier Transform (FFT)**
    ```python
    import numpy as np
    fft_vals = np.fft.fft(audio)
    plt.plot(np.abs(fft_vals))
    plt.title("Fourier Transform")
    plt.show()
    ```

12. **Plot Power Spectral Density (PSD)**
    ```python
    import scipy.signal
    f, Pxx = scipy.signal.welch(audio, sr)
    plt.semilogy(f, Pxx)
    plt.title("Power Spectral Density")
    plt.show()
    ```

13. **Visualize Mel-Frequency Cepstral Coefficients (MFCCs)**
    ```python
    mfcc = librosa.feature.mfcc(y=audio, sr=sr)
    plt.imshow(mfcc, cmap='viridis', aspect='auto', origin='lower')
    plt.title("MFCCs")
    plt.show()
    ```

14. **Plot Mel Spectrogram**
    ```python
    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)
    librosa.display.specshow(librosa.power_to_db(mel_spectrogram, ref=np.max), y_axis='mel', x_axis='time')
    plt.title("Mel Spectrogram")
    plt.show()
    ```

15. **Compute Chromagram (Pitch)**
    ```python
    chroma = librosa.feature.chroma_stft(y=audio, sr=sr)
    librosa.display.specshow(chroma, y_axis='chroma', x_axis='time')
    plt.title("Chromagram")
    plt.show()
    ```

---

### **4. Signal Processing**
16. **Apply High-Pass Filter**
    ```python
    from scipy.signal import butter, lfilter
    def highpass_filter(data, cutoff, fs, order=5):
        nyquist = 0.5 * fs
        normal_cutoff = cutoff / nyquist
        b, a = butter(order, normal_cutoff, btype='high', analog=False)
        return lfilter(b, a, data)
    filtered_audio = highpass_filter(audio, 1000, sr)
    ```

17. **Apply Low-Pass Filter**
    ```python
    def lowpass_filter(data, cutoff, fs, order=5):
        nyquist = 0.5 * fs
        normal_cutoff = cutoff / nyquist
        b, a = butter(order, normal_cutoff, btype='low', analog=False)
        return lfilter(b, a, data)
    filtered_audio = lowpass_filter(audio, 500, sr)
    ```

18. **Normalize Audio Signal**
    ```python
    normalized_audio = librosa.util.normalize(audio)
    plt.plot(normalized_audio)
    plt.title("Normalized Audio Signal")
    plt.show()
    ```

19. **Resample Audio to Different Sampling Rate**
    ```python
    audio_resampled = librosa.resample(audio, sr, 16000)
    ```

20. **Visualize Phase Vocoder**
    ```python
    stft = librosa.stft(audio)
    stft_vocoder = librosa.phase_vocoder(stft, rate=1.2)
    librosa.display.specshow(librosa.amplitude_to_db(abs(stft_vocoder), ref=np.max), y_axis='log', x_axis='time')
    plt.title("Phase Vocoder Spectrogram")
    plt.show()
    ```

---

### **5. Temporal and Amplitude Analysis**
21. **Compute Temporal Features (Mean, Min, Max)**
    ```python
    mean_amplitude = np.mean(audio)
    min_amplitude = np.min(audio)
    max_amplitude = np.max(audio)
    print(f"Mean: {mean_amplitude}, Min: {min_amplitude}, Max: {max_amplitude}")
    ```

22. **Plot Envelope of Amplitude Peaks**
    ```python
    peaks = librosa.onset.onset_detect(y=audio, sr=sr)
    plt.plot(audio)
    plt.scatter(peaks, audio[peaks], color='red')
    plt.title("Amplitude Peaks")
    plt.show()
    ```

23. **Compute Autocorrelation**
    ```python
    autocorr = np.correlate(audio, audio, mode='full')
    plt.plot(autocorr)
    plt.title("Autocorrelation")
    plt.show()
    ```

24. **Compute Signal Entropy**
    ```python
    from scipy.stats import entropy
    signal_entropy = entropy(np.histogram(audio, bins=50)[0])
    print(f"Signal Entropy: {signal_entropy}")
    ```

25. **Calculate Signal Skewness and Kurtosis**
    ```python
    from scipy.stats import skew, kurtosis
    signal_skew = skew(audio)
    signal_kurt = kurtosis(audio)
    print(f"Skewness: {signal_skew}, Kurtosis: {signal_kurt}")
    ```

---

### **6. Feature Extraction**
26. **Extract Spectral Contrast**
    ```python
    spectral_contrast = librosa.feature.spectral_contrast(y=audio, sr=sr)
    plt.imshow(spectral_contrast, cmap='viridis', aspect='auto', origin='lower')
    plt.title("Spectral Contrast")
    plt.show()
    ```

27. **Compute Spectral Bandwidth**
    ```python
    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr)
    plt.plot(spectral_bandwidth[0])
    plt.title("Spectral Bandwidth")
    plt.show()
    ```

28. **Extract Tonnetz (Harmonic Relations)**
    ```python
    tonnetz = librosa.feature.tonnetz(y=audio, sr=sr)
    plt.plot(tonnetz[0])
    plt.title("Tonnetz (Harmonic Relations)")
    plt.show()
    ```

29. **Extract Spectral Rolloff**
    ```python
    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr, rolloff=0.85)
    plt.plot(spectral_rolloff[0])
    plt.title("Spectral Rolloff")
    plt.show()
    ```

30. **Compute Root Mean Square (RMS) Energy**
    ```python
    rms_energy = librosa.feature.rms(y=audio)
    plt.plot(rms_energy[0])
    plt.title("RMS Energy")
    plt.show()
    ```

---

### **7. Temporal Patterns and Onsets**
31. **Visualize Onsets (Audio Events)**
    ```python
    onsets = librosa.onset.onset_detect(y=audio, sr=sr)
    plt.plot(audio)
    plt.scatter(onsets, audio[onsets], color='red')
    plt.title("Onset Detection")
    plt.show()
    ```

32. **Compute Tempo (Beats per Minute)**
    ```python
    tempo, beats = librosa.beat.beat_track(y=audio, sr=sr)
    print(f"Estimated Tempo: {tempo} BPM")
    ```

33. **Detect Onset Strength**
    ```python
    onset_strength = librosa.onset.onset_strength(y=audio, sr=sr)
    plt.plot(onset_strength)
    plt.title("Onset Strength")
    plt.show()
    ```

34. **Visualize the Beat Periodicity**
    ```python
    beat_times = librosa.frames_to_time(beats, sr=sr)
    plt.plot(beat_times)
    plt.title("Beat Periodicity")
    plt.show()
    ```

35. **Calculate Beat Energy**
    ```python
    beat_energy = librosa.feature.rms(y=audio, frame_length=2048, hop_length=512)
    plt.plot(beat_energy[0])
    plt.title("Beat Energy")
    plt.show()
    ```

---

### **8. Audio Preprocessing**
36. **Perform Noise Reduction**
    ```python
    from noisereduce import reduce_noise
    reduced_audio = reduce_noise(y=audio, sr=sr)
    ```

37. **Apply Audio Compression**
    ```python
    compressed_audio = librosa.effects.time_stretch(audio, 1.5)
    ```

38. **Apply Pitch Shift**
    ```python
    pitch_shifted_audio = librosa.effects.pitch_shift(audio, sr, n_steps=2)
    ```

39. **Apply Time Stretch**
    ```python
    time_stretched_audio = librosa.effects.time_stretch(audio, rate=1.2)
    ```

40. **Segment Audio into Chunks**
    ```python
    chunk_size = 22050  # 1 second of audio at 22.05 kHz
    audio_chunks = [audio[i:i + chunk_size] for i in range(0, len(audio), chunk_size)]
    ```

---

### **9. Audio Data Transformation**
41. **Transform Audio to Log-Magnitude Spectrogram**
    ```python
    S = librosa.amplitude_to_db(np.abs(librosa.stft(audio)), ref=np.max)
    librosa.display.specshow(S, y_axis='log', x_axis='time')
    plt.title("Log-Magnitude Spectrogram")
    plt.show()
    ```

42. **Convert Audio to Mel Spectrogram**
    ```python
    mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr)
    librosa.display.specshow(librosa.power_to_db(mel_spec, ref=np.max), y_axis='mel', x_axis='time')
    plt.title("Mel Spectrogram")
    plt.show()
    ```

43. **Apply Short-Time Fourier Transform (STFT)**
    ```python
    D = librosa.stft(audio)
    librosa.display.specshow(librosa.amplitude_to_db(np.abs(D), ref=np.max), y_axis='log', x_axis='time')
    plt.title("STFT")
    plt.show()
    ```

44. **Compute Signal Envelope**
    ```python
    envelope = librosa.onset.onset_strength(y=audio, sr=sr)
    plt.plot(envelope)
    plt.title("Envelope of the Signal")
    plt.show()
    ```

45. **Generate Audio File from Processed Data**
    ```python
    librosa.output.write_wav('processed_audio.wav', reduced_audio, sr)
    ```

---

### **10. Advanced Audio Analysis and Machine Learning**
46. **Train Classifier on Extracted Features (e.g., MFCC, Chroma)**
    ```python
    from sklearn.ensemble import RandomForestClassifier
    features = np.vstack([librosa.feature.mfcc(y=audio, sr=sr).T for audio in audio_samples])
    labels = np.array([label for label in audio_labels])
    clf = RandomForestClassifier()
    clf.fit(features, labels)
    ```

47. **Visualize Feature Distribution (MFCC)**
    ```python
    mfccs = librosa.feature.mfcc(y=audio, sr=sr)
    plt.imshow(mfccs, cmap='viridis', aspect='auto', origin='lower')
    plt.title("MFCC Feature Distribution")
    plt.show()
    ```

48. **Use PCA for Dimensionality Reduction on Features**
    ```python
    from sklearn.decomposition import PCA
    pca = PCA(n_components=2)
    transformed_features = pca.fit_transform(features)
    plt.scatter(transformed_features[:, 0], transformed_features[:, 1], c=labels)
    plt.title("PCA on Audio Features")
    plt.show()
    ```

49. **Compute Correlation Between Features**
    ```python
    import seaborn as sns
    correlation_matrix = np.corrcoef(features.T)
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
    plt.title("Correlation Matrix of Audio Features")
    plt.show()
    ```

50. **Classify Audio Based on Extracted Features**
    ```python
    from sklearn.svm import SVC
    svm_clf = SVC()
    svm_clf.fit(features, labels)
    ```

---

The remaining steps would cover advanced machine learning modeling, visualization, and transformation techniques. You could also explore using deep learning for audio classification, feature extraction, and anomaly detection.


